{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## \"AIgators\" team submission for SPE GCS ML Competition\n",
    "## by Jamal Ahmadov, Cristina Mariana Ruse, Rodrigue Rizk\n",
    "## University of Louisiana at Lafayette"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sklearn\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import os\n",
    "import glob\n",
    "import seaborn as sns\n",
    "from sklearn.model_selection import StratifiedShuffleSplit\n",
    "from sklearn.model_selection import train_test_split\n",
    "import lasio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Change directory\n",
    "os.chdir(\"C:/Users/Jamal/Downloads/ML SPE competition-take home/ML Challenge Data - modified - techlog\")\n",
    "# Create a list with all the files\n",
    "path = os.getcwd()\n",
    "files = os.listdir(path)\n",
    "# Select only xlsx files\n",
    "files_las = [f for f in files if f[-3:] == \"las\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## All logs with well names appended"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "lst=[]\n",
    "lst2=[]\n",
    "\n",
    "# Loop over list of Excel files\n",
    "for f in files_las: \n",
    "    las=lasio.read(f)\n",
    "    df=las.df()\n",
    "    df.reset_index(inplace=True)\n",
    "    lst.append(df)\n",
    "    \n",
    "    well_name = pd.DataFrame([f] * df.shape[0])\n",
    "    lst2.append(well_name)\n",
    "    \n",
    "df2=pd.concat(lst,axis=0)\n",
    "df_names=pd.concat(lst2,axis=0)\n",
    "\n",
    "df_wells=pd.concat([df2,df_names],axis=1)\n",
    "df_wells.rename(columns={0:\"Well name\"},inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Coordinates and well names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Latitude</th>\n",
       "      <th>Longtitude</th>\n",
       "      <th>Well name</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.678958</td>\n",
       "      <td>6.390539</td>\n",
       "      <td>0052442d0162_TGS.las</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3.680670</td>\n",
       "      <td>7.095404</td>\n",
       "      <td>00a60e5cc262_TGS.las</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2.763908</td>\n",
       "      <td>9.104955</td>\n",
       "      <td>01c726e0fabe_TGS.las</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2.299873</td>\n",
       "      <td>5.807630</td>\n",
       "      <td>02571837c35f_TGS.las</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1.404772</td>\n",
       "      <td>8.618104</td>\n",
       "      <td>03d4fc789db8_TGS.las</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>229</th>\n",
       "      <td>3.361701</td>\n",
       "      <td>7.688234</td>\n",
       "      <td>fb82f07561bd_TGS.las</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>230</th>\n",
       "      <td>5.515475</td>\n",
       "      <td>2.537780</td>\n",
       "      <td>fc913430daa9_TGS.las</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>231</th>\n",
       "      <td>2.048852</td>\n",
       "      <td>8.203397</td>\n",
       "      <td>fcd64679cafa_TGS.las</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>232</th>\n",
       "      <td>6.216308</td>\n",
       "      <td>3.438106</td>\n",
       "      <td>fe47e0c3ac55_TGS.las</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>233</th>\n",
       "      <td>2.824751</td>\n",
       "      <td>8.884746</td>\n",
       "      <td>fe8ab5538224_TGS.las</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>234 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     Latitude  Longtitude             Well name\n",
       "0    1.678958    6.390539  0052442d0162_TGS.las\n",
       "1    3.680670    7.095404  00a60e5cc262_TGS.las\n",
       "2    2.763908    9.104955  01c726e0fabe_TGS.las\n",
       "3    2.299873    5.807630  02571837c35f_TGS.las\n",
       "4    1.404772    8.618104  03d4fc789db8_TGS.las\n",
       "..        ...         ...                   ...\n",
       "229  3.361701    7.688234  fb82f07561bd_TGS.las\n",
       "230  5.515475    2.537780  fc913430daa9_TGS.las\n",
       "231  2.048852    8.203397  fcd64679cafa_TGS.las\n",
       "232  6.216308    3.438106  fe47e0c3ac55_TGS.las\n",
       "233  2.824751    8.884746  fe8ab5538224_TGS.las\n",
       "\n",
       "[234 rows x 3 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Lat=[]\n",
    "\n",
    "# Loop over list of Excel files\n",
    "for f in files_las:\n",
    "    \n",
    "    las=lasio.read(f)\n",
    "    Lat.append({'Latitude':las.well['SLAT'].value,'Longtitude':las.well['SLON'].value,'Well name':f})\n",
    "\n",
    "df_cord=pd.DataFrame(Lat)\n",
    "df_cord"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## All mnemonics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "clmn=df2.columns\n",
    "clmn_df=pd.DataFrame(clmn)\n",
    "clmn_df.columns=['Property']\n",
    "clmn_df.sort_values('Property',inplace=True)\n",
    "clmn_df.reset_index(drop=True,inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## All curves description with well names appended"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Mnemonic</th>\n",
       "      <th>Unit</th>\n",
       "      <th>Description</th>\n",
       "      <th>Latitude</th>\n",
       "      <th>Longtitude</th>\n",
       "      <th>Well name</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>DEPT</td>\n",
       "      <td>F</td>\n",
       "      <td>1 MEASURED DEPTH</td>\n",
       "      <td>1.678958</td>\n",
       "      <td>6.390539</td>\n",
       "      <td>0052442d0162_TGS.las</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>DTCO</td>\n",
       "      <td>US/F</td>\n",
       "      <td>DELTA-T COMPRESSIONAL</td>\n",
       "      <td>1.678958</td>\n",
       "      <td>6.390539</td>\n",
       "      <td>0052442d0162_TGS.las</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>GRS</td>\n",
       "      <td>GAPI</td>\n",
       "      <td>GAMMA RAY FROM SONIC LOG</td>\n",
       "      <td>1.678958</td>\n",
       "      <td>6.390539</td>\n",
       "      <td>0052442d0162_TGS.las</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>DTSM</td>\n",
       "      <td>US/F</td>\n",
       "      <td>DELTA-T SHEAR</td>\n",
       "      <td>1.678958</td>\n",
       "      <td>6.390539</td>\n",
       "      <td>0052442d0162_TGS.las</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>DEPT</td>\n",
       "      <td>ft</td>\n",
       "      <td></td>\n",
       "      <td>3.680670</td>\n",
       "      <td>7.095404</td>\n",
       "      <td>00a60e5cc262_TGS.las</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3275</th>\n",
       "      <td>RHOZ</td>\n",
       "      <td>G/C3</td>\n",
       "      <td>HRDD STANDARD RESOLUTION FORMATION DENSITY</td>\n",
       "      <td>2.824751</td>\n",
       "      <td>8.884746</td>\n",
       "      <td>fe8ab5538224_TGS.las</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3276</th>\n",
       "      <td>RLA3</td>\n",
       "      <td>OHMM</td>\n",
       "      <td>APPARENT RESISTIVITY FROM COMPUTED FOCUSING MO...</td>\n",
       "      <td>2.824751</td>\n",
       "      <td>8.884746</td>\n",
       "      <td>fe8ab5538224_TGS.las</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3277</th>\n",
       "      <td>RLA5</td>\n",
       "      <td>OHMM</td>\n",
       "      <td>APPARENT RESISTIVITY FROM COMPUTED FOCUSING MO...</td>\n",
       "      <td>2.824751</td>\n",
       "      <td>8.884746</td>\n",
       "      <td>fe8ab5538224_TGS.las</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3278</th>\n",
       "      <td>RXOZ</td>\n",
       "      <td>OHMM</td>\n",
       "      <td>INVADED FORMATION RESISTIVITY FILTERED AT 18 I...</td>\n",
       "      <td>2.824751</td>\n",
       "      <td>8.884746</td>\n",
       "      <td>fe8ab5538224_TGS.las</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3279</th>\n",
       "      <td>TNPH_LS</td>\n",
       "      <td>DEC</td>\n",
       "      <td>THERMAL NEUTRON POROSITY [LIMESTONE]</td>\n",
       "      <td>2.824751</td>\n",
       "      <td>8.884746</td>\n",
       "      <td>fe8ab5538224_TGS.las</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3280 rows × 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     Mnemonic  Unit                                        Description  \\\n",
       "0        DEPT     F                                   1 MEASURED DEPTH   \n",
       "1        DTCO  US/F                              DELTA-T COMPRESSIONAL   \n",
       "2         GRS  GAPI                           GAMMA RAY FROM SONIC LOG   \n",
       "3        DTSM  US/F                                      DELTA-T SHEAR   \n",
       "4        DEPT    ft                                                      \n",
       "...       ...   ...                                                ...   \n",
       "3275     RHOZ  G/C3         HRDD STANDARD RESOLUTION FORMATION DENSITY   \n",
       "3276     RLA3  OHMM  APPARENT RESISTIVITY FROM COMPUTED FOCUSING MO...   \n",
       "3277     RLA5  OHMM  APPARENT RESISTIVITY FROM COMPUTED FOCUSING MO...   \n",
       "3278     RXOZ  OHMM  INVADED FORMATION RESISTIVITY FILTERED AT 18 I...   \n",
       "3279  TNPH_LS   DEC               THERMAL NEUTRON POROSITY [LIMESTONE]   \n",
       "\n",
       "      Latitude  Longtitude             Well name  \n",
       "0     1.678958    6.390539  0052442d0162_TGS.las  \n",
       "1     1.678958    6.390539  0052442d0162_TGS.las  \n",
       "2     1.678958    6.390539  0052442d0162_TGS.las  \n",
       "3     1.678958    6.390539  0052442d0162_TGS.las  \n",
       "4     3.680670    7.095404  00a60e5cc262_TGS.las  \n",
       "...        ...         ...                   ...  \n",
       "3275  2.824751    8.884746  fe8ab5538224_TGS.las  \n",
       "3276  2.824751    8.884746  fe8ab5538224_TGS.las  \n",
       "3277  2.824751    8.884746  fe8ab5538224_TGS.las  \n",
       "3278  2.824751    8.884746  fe8ab5538224_TGS.las  \n",
       "3279  2.824751    8.884746  fe8ab5538224_TGS.las  \n",
       "\n",
       "[3280 rows x 6 columns]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "logs=[]\n",
    "a_list = []\n",
    "b_list = []\n",
    "c_list = []\n",
    "Lat=[]\n",
    "Lon=[]\n",
    "w_list=[]\n",
    "\n",
    "for f in files_las: \n",
    "    las=lasio.read(f)\n",
    "    colnum=las.keys()\n",
    "    logs=las.curves\n",
    "    for i in range(0,len(colnum)):\n",
    "        a=logs[i]['descr']\n",
    "        a_list.append(a)\n",
    "        b=logs[i]['unit']\n",
    "        b_list.append(b)\n",
    "        c=logs[i]['mnemonic']\n",
    "        c_list.append(c)\n",
    "        Lat.append(las.well['SLAT'].value)\n",
    "        Lon.append(las.well['SLON'].value)\n",
    "        w_list.append(f)\n",
    "\n",
    "df_curves = pd.DataFrame({'Mnemonic': c_list, 'Unit': b_list,'Description': a_list,'Latitude': Lat,'Longtitude': Lon,\n",
    "                               'Well name': w_list})\n",
    "df_curves"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Function to select only logs needed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def log_count(df,name):\n",
    "    prop=df.groupby(['Latitude', 'Longtitude']).size().rename(name+'_count').sort_values(ascending=False)\n",
    "    df_f=pd.DataFrame(prop).reset_index()\n",
    "    return df_f"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Resistivity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "comp_df_res=df_curves[(df_curves['Mnemonic']=='AE90') | (df_curves['Mnemonic']=='AF90') | (df_curves['Mnemonic']=='AHT90') \n",
    "                 | (df_curves['Mnemonic']=='AO90') | (df_curves['Mnemonic']=='AST90') | (df_curves['Mnemonic']=='AT90')\n",
    "                 | (df_curves['Mnemonic']=='HLLD') | (df_curves['Mnemonic']=='HRID') | (df_curves['Mnemonic']=='IDPH')\n",
    "                 | (df_curves['Mnemonic']=='ILD')| (df_curves['Mnemonic']=='LLD') | (df_curves['Mnemonic']=='LLD_R')\n",
    "                 | (df_curves['Mnemonic']=='RILD') | (df_curves['Mnemonic']=='RLA5') | (df_curves['Mnemonic']=='TBIT90')]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Neutron"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "comp_df_neut=df_curves[(df_curves['Mnemonic']=='APLCLS') | (df_curves['Mnemonic']=='APLC_LS') | (df_curves['Mnemonic']=='CNC') \n",
    "                 | (df_curves['Mnemonic']=='CNC_LS') | (df_curves['Mnemonic']=='CNPOR_LS') | (df_curves['Mnemonic']=='TNPH_LIM')\n",
    "                 | (df_curves['Mnemonic']=='TNPH_LS') | (df_curves['Mnemonic']=='TPHI_LS') | (df_curves['Mnemonic']=='SNP')\n",
    "                 | (df_curves['Mnemonic']=='NPOR')| (df_curves['Mnemonic']=='NPORLS') | (df_curves['Mnemonic']=='NPOR_LS')\n",
    "                 | (df_curves['Mnemonic']=='NPHS') | (df_curves['Mnemonic']=='NPHI_LS') | (df_curves['Mnemonic']=='NPHILS')\n",
    "                | (df_curves['Mnemonic']=='NPHI') | (df_curves['Mnemonic']=='ENPH_LS')| (df_curves['Mnemonic']=='TNPH')]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Density porosity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "comp_df_densp=df_curves[(df_curves['Mnemonic']=='DPHI') | (df_curves['Mnemonic']=='DPHILS') | (df_curves['Mnemonic']=='DPHI_LS') \n",
    "                 | (df_curves['Mnemonic']=='DPHI_SLDT') | (df_curves['Mnemonic']=='DPHZ') | (df_curves['Mnemonic']=='DPHZLS')\n",
    "                 | (df_curves['Mnemonic']=='DPHZ_LS') | (df_curves['Mnemonic']=='DPO') | (df_curves['Mnemonic']=='DPOR')\n",
    "                 | (df_curves['Mnemonic']=='DPOR_LS')| (df_curves['Mnemonic']=='DPO_LS') | (df_curves['Mnemonic']=='PHND_LS')\n",
    "                 | (df_curves['Mnemonic']=='PORZ_LS')]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Density"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "comp_df_dens=df_curves[(df_curves['Mnemonic']=='NRHO') | (df_curves['Mnemonic']=='RHOB') | (df_curves['Mnemonic']=='RHOB_SLDT') \n",
    "                 | (df_curves['Mnemonic']=='RHOZ') | (df_curves['Mnemonic']=='ZDEN') | (df_curves['Mnemonic']=='RHOM')]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Gamma ray"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "comp_df_gr=df_curves[(df_curves['Mnemonic']=='ECGR') | (df_curves['Mnemonic']=='ECGRD') | (df_curves['Mnemonic']=='ECGREDTC') \n",
    "                 | (df_curves['Mnemonic']=='ECGRR') | (df_curves['Mnemonic']=='ECGRS') | (df_curves['Mnemonic']=='GR')\n",
    "                | (df_curves['Mnemonic']=='GRC') | (df_curves['Mnemonic']=='GRD') | (df_curves['Mnemonic']=='GRD1')\n",
    "                | (df_curves['Mnemonic']=='GRN') | (df_curves['Mnemonic']=='GRR') | (df_curves['Mnemonic']=='GRS')\n",
    "                | (df_curves['Mnemonic']=='GRT') | (df_curves['Mnemonic']=='GR_EDTC') | (df_curves['Mnemonic']=='GR_STGC')\n",
    "                | (df_curves['Mnemonic']=='HCGR') | (df_curves['Mnemonic']=='HCGRD') | (df_curves['Mnemonic']=='HCGRR')\n",
    "                | (df_curves['Mnemonic']=='HCGRS') | (df_curves['Mnemonic']=='HGRT') | (df_curves['Mnemonic']=='HSGR')\n",
    "                | (df_curves['Mnemonic']=='HSGRD') | (df_curves['Mnemonic']=='HSGRR') | (df_curves['Mnemonic']=='HSGRS')\n",
    "                    | (df_curves['Mnemonic']=='SGRDD') | (df_curves['Mnemonic']=='SGRS')]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Photoelectric"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "comp_df_pe=df_curves[(df_curves['Mnemonic']=='PE') | (df_curves['Mnemonic']=='PEF') | (df_curves['Mnemonic']=='PEFL') \n",
    "                 | (df_curves['Mnemonic']=='PEFS') | (df_curves['Mnemonic']=='PEFZ') | (df_curves['Mnemonic']=='PEF_SLDT')]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Compressional"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "comp_df_compr=df_curves[(df_curves['Mnemonic']=='DTCO') | (df_curves['Mnemonic']=='DTLF') | (df_curves['Mnemonic']=='DT')\n",
    "                       | (df_curves['Mnemonic']=='DT4P') | (df_curves['Mnemonic']=='DTCM')]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Shear"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "comp_df_shear=df_curves[(df_curves['Mnemonic']=='DTSM')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Mnemonic</th>\n",
       "      <th>Unit</th>\n",
       "      <th>Description</th>\n",
       "      <th>Latitude</th>\n",
       "      <th>Longtitude</th>\n",
       "      <th>Well name</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1275</th>\n",
       "      <td>AT10</td>\n",
       "      <td>OHMM</td>\n",
       "      <td>ARRAY INDUCTION TWO FOOT RESISTIVITY A10</td>\n",
       "      <td>6.725493</td>\n",
       "      <td>3.908037</td>\n",
       "      <td>734da1169c53_TGS.las</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>327</th>\n",
       "      <td>NPHI_LS</td>\n",
       "      <td>DEC</td>\n",
       "      <td>NEUTRON POROSITY LIMESTONE</td>\n",
       "      <td>6.788468</td>\n",
       "      <td>3.401863</td>\n",
       "      <td>19ed10214869_TGS.las</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>326</th>\n",
       "      <td>DEPT</td>\n",
       "      <td>F</td>\n",
       "      <td>1 MEASURED DEPTH</td>\n",
       "      <td>6.788468</td>\n",
       "      <td>3.401863</td>\n",
       "      <td>19ed10214869_TGS.las</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>328</th>\n",
       "      <td>DT</td>\n",
       "      <td>US/F</td>\n",
       "      <td>DELTA-T (INTERVAL TRANSIT TIME)</td>\n",
       "      <td>6.788468</td>\n",
       "      <td>3.401863</td>\n",
       "      <td>19ed10214869_TGS.las</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>331</th>\n",
       "      <td>DT1</td>\n",
       "      <td>US/F</td>\n",
       "      <td>DELTA-T SHEAR - LOWER DIPOLE</td>\n",
       "      <td>6.788468</td>\n",
       "      <td>3.401863</td>\n",
       "      <td>19ed10214869_TGS.las</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>330</th>\n",
       "      <td>GRS</td>\n",
       "      <td>GAPI</td>\n",
       "      <td>GAMMA RAY FROM SONIC LOG</td>\n",
       "      <td>6.788468</td>\n",
       "      <td>3.401863</td>\n",
       "      <td>19ed10214869_TGS.las</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>329</th>\n",
       "      <td>DTSM</td>\n",
       "      <td>US/F</td>\n",
       "      <td>DELTA-T SHEAR</td>\n",
       "      <td>6.788468</td>\n",
       "      <td>3.401863</td>\n",
       "      <td>19ed10214869_TGS.las</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>332</th>\n",
       "      <td>DTCO</td>\n",
       "      <td>US/F</td>\n",
       "      <td>DELTA-T COMPRESSIONAL</td>\n",
       "      <td>6.788468</td>\n",
       "      <td>3.401863</td>\n",
       "      <td>19ed10214869_TGS.las</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>681</th>\n",
       "      <td>TNPH_LS</td>\n",
       "      <td>DEC</td>\n",
       "      <td>THERMAL NEUTRON POROSITY [LIMESTONE]</td>\n",
       "      <td>6.930438</td>\n",
       "      <td>3.417693</td>\n",
       "      <td>4460f43fb0fd_TGS.las</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>680</th>\n",
       "      <td>TENS</td>\n",
       "      <td>LBF</td>\n",
       "      <td>TENSION FROM SONIC LOG</td>\n",
       "      <td>6.930438</td>\n",
       "      <td>3.417693</td>\n",
       "      <td>4460f43fb0fd_TGS.las</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>679</th>\n",
       "      <td>TENR</td>\n",
       "      <td>LBF</td>\n",
       "      <td>TENSION FROM RESISTIVITY LOG</td>\n",
       "      <td>6.930438</td>\n",
       "      <td>3.417693</td>\n",
       "      <td>4460f43fb0fd_TGS.las</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>678</th>\n",
       "      <td>SPHI_LS</td>\n",
       "      <td>DEC</td>\n",
       "      <td>SONIC POROSITY [LIMESTONE]</td>\n",
       "      <td>6.930438</td>\n",
       "      <td>3.417693</td>\n",
       "      <td>4460f43fb0fd_TGS.las</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>677</th>\n",
       "      <td>PEFZ</td>\n",
       "      <td>B/E</td>\n",
       "      <td>HRDD STANDARD RESOLUTION FORMATION PHOTOELECTR...</td>\n",
       "      <td>6.930438</td>\n",
       "      <td>3.417693</td>\n",
       "      <td>4460f43fb0fd_TGS.las</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>676</th>\n",
       "      <td>HCALS</td>\n",
       "      <td>IN</td>\n",
       "      <td>HRCC CALIPER CALIBRATED FROM SONIC LOG</td>\n",
       "      <td>6.930438</td>\n",
       "      <td>3.417693</td>\n",
       "      <td>4460f43fb0fd_TGS.las</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>673</th>\n",
       "      <td>DTCO</td>\n",
       "      <td>US/F</td>\n",
       "      <td>DELTA-T COMPRESSIONAL</td>\n",
       "      <td>6.930438</td>\n",
       "      <td>3.417693</td>\n",
       "      <td>4460f43fb0fd_TGS.las</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>672</th>\n",
       "      <td>DPHZ_LS</td>\n",
       "      <td>DEC</td>\n",
       "      <td>HGRD STANDARD RESOLUTION DENSITY POROSITY</td>\n",
       "      <td>6.930438</td>\n",
       "      <td>3.417693</td>\n",
       "      <td>4460f43fb0fd_TGS.las</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>671</th>\n",
       "      <td>AT90</td>\n",
       "      <td>OHMM</td>\n",
       "      <td>ARRAY INDUCTION TWO FOOT RESISTIVITY A90</td>\n",
       "      <td>6.930438</td>\n",
       "      <td>3.417693</td>\n",
       "      <td>4460f43fb0fd_TGS.las</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>669</th>\n",
       "      <td>AT30</td>\n",
       "      <td>OHMM</td>\n",
       "      <td>ARRAY INDUCTION TWO FOOT RESISTIVITY A30</td>\n",
       "      <td>6.930438</td>\n",
       "      <td>3.417693</td>\n",
       "      <td>4460f43fb0fd_TGS.las</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>668</th>\n",
       "      <td>AT20</td>\n",
       "      <td>OHMM</td>\n",
       "      <td>ARRAY INDUCTION TWO FOOT RESISTIVITY A20</td>\n",
       "      <td>6.930438</td>\n",
       "      <td>3.417693</td>\n",
       "      <td>4460f43fb0fd_TGS.las</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>667</th>\n",
       "      <td>AT10</td>\n",
       "      <td>OHMM</td>\n",
       "      <td>ARRAY INDUCTION TWO FOOT RESISTIVITY A10</td>\n",
       "      <td>6.930438</td>\n",
       "      <td>3.417693</td>\n",
       "      <td>4460f43fb0fd_TGS.las</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     Mnemonic  Unit                                        Description  \\\n",
       "1275     AT10  OHMM           ARRAY INDUCTION TWO FOOT RESISTIVITY A10   \n",
       "327   NPHI_LS   DEC                         NEUTRON POROSITY LIMESTONE   \n",
       "326      DEPT     F                                   1 MEASURED DEPTH   \n",
       "328        DT  US/F                    DELTA-T (INTERVAL TRANSIT TIME)   \n",
       "331       DT1  US/F                       DELTA-T SHEAR - LOWER DIPOLE   \n",
       "330       GRS  GAPI                           GAMMA RAY FROM SONIC LOG   \n",
       "329      DTSM  US/F                                      DELTA-T SHEAR   \n",
       "332      DTCO  US/F                              DELTA-T COMPRESSIONAL   \n",
       "681   TNPH_LS   DEC               THERMAL NEUTRON POROSITY [LIMESTONE]   \n",
       "680      TENS   LBF                             TENSION FROM SONIC LOG   \n",
       "679      TENR   LBF                       TENSION FROM RESISTIVITY LOG   \n",
       "678   SPHI_LS   DEC                         SONIC POROSITY [LIMESTONE]   \n",
       "677      PEFZ   B/E  HRDD STANDARD RESOLUTION FORMATION PHOTOELECTR...   \n",
       "676     HCALS    IN             HRCC CALIPER CALIBRATED FROM SONIC LOG   \n",
       "673      DTCO  US/F                              DELTA-T COMPRESSIONAL   \n",
       "672   DPHZ_LS   DEC          HGRD STANDARD RESOLUTION DENSITY POROSITY   \n",
       "671      AT90  OHMM           ARRAY INDUCTION TWO FOOT RESISTIVITY A90   \n",
       "669      AT30  OHMM           ARRAY INDUCTION TWO FOOT RESISTIVITY A30   \n",
       "668      AT20  OHMM           ARRAY INDUCTION TWO FOOT RESISTIVITY A20   \n",
       "667      AT10  OHMM           ARRAY INDUCTION TWO FOOT RESISTIVITY A10   \n",
       "\n",
       "      Latitude  Longtitude             Well name  \n",
       "1275  6.725493    3.908037  734da1169c53_TGS.las  \n",
       "327   6.788468    3.401863  19ed10214869_TGS.las  \n",
       "326   6.788468    3.401863  19ed10214869_TGS.las  \n",
       "328   6.788468    3.401863  19ed10214869_TGS.las  \n",
       "331   6.788468    3.401863  19ed10214869_TGS.las  \n",
       "330   6.788468    3.401863  19ed10214869_TGS.las  \n",
       "329   6.788468    3.401863  19ed10214869_TGS.las  \n",
       "332   6.788468    3.401863  19ed10214869_TGS.las  \n",
       "681   6.930438    3.417693  4460f43fb0fd_TGS.las  \n",
       "680   6.930438    3.417693  4460f43fb0fd_TGS.las  \n",
       "679   6.930438    3.417693  4460f43fb0fd_TGS.las  \n",
       "678   6.930438    3.417693  4460f43fb0fd_TGS.las  \n",
       "677   6.930438    3.417693  4460f43fb0fd_TGS.las  \n",
       "676   6.930438    3.417693  4460f43fb0fd_TGS.las  \n",
       "673   6.930438    3.417693  4460f43fb0fd_TGS.las  \n",
       "672   6.930438    3.417693  4460f43fb0fd_TGS.las  \n",
       "671   6.930438    3.417693  4460f43fb0fd_TGS.las  \n",
       "669   6.930438    3.417693  4460f43fb0fd_TGS.las  \n",
       "668   6.930438    3.417693  4460f43fb0fd_TGS.las  \n",
       "667   6.930438    3.417693  4460f43fb0fd_TGS.las  "
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_curves.sort_values(by=['Latitude'])[3185:3205]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Caliper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "comp_df_calip=df_curves[(df_curves['Mnemonic']=='CAL1R') | (df_curves['Mnemonic']=='CALD') | (df_curves['Mnemonic']=='CALI') \n",
    "                 | (df_curves['Mnemonic']=='CALI_SPCS') | (df_curves['Mnemonic']=='CALR') | (df_curves['Mnemonic']=='CALS')\n",
    "                | (df_curves['Mnemonic']=='CALSR') | (df_curves['Mnemonic']=='CALSR_R') | (df_curves['Mnemonic']=='CALX')\n",
    "                | (df_curves['Mnemonic']=='HCAL') | (df_curves['Mnemonic']=='HCALD') | (df_curves['Mnemonic']=='HCALR')\n",
    "               | (df_curves['Mnemonic']=='HCALS') | (df_curves['Mnemonic']=='HD') | (df_curves['Mnemonic']=='HD1')\n",
    "                | (df_curves['Mnemonic']=='HD1_PPC1') | (df_curves['Mnemonic']=='HD2_PPC2') | (df_curves['Mnemonic']=='LCAL')\n",
    "                | (df_curves['Mnemonic']=='LCALD') | (df_curves['Mnemonic']=='LCALR') | (df_curves['Mnemonic']=='C1')\n",
    "                       | (df_curves['Mnemonic']=='C1S')]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Density correction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "comp_df_denscorr=df_curves[(df_curves['Mnemonic']=='HDRA') | (df_curves['Mnemonic']=='DRHO') | (df_curves['Mnemonic']=='DRH')\n",
    "                          | (df_curves['Mnemonic']=='ZCOR') | (df_curves['Mnemonic']=='DCOR') | (df_curves['Mnemonic']=='CORR')]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Merging well logs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfs=[log_count(comp_df_res,'res'),log_count(comp_df_neut,'neutron'),log_count(comp_df_dens,'dens'),log_count(comp_df_densp,'densp'),\n",
    "         log_count(comp_df_gr,'gr'), log_count(comp_df_pe,'pe'),log_count(comp_df_compr,'compr'),log_count(comp_df_shear,'shear'),\n",
    "         log_count(comp_df_calip,'calip'),log_count(comp_df_denscorr,'denscorr')]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Counting number of curves in each well"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_0=pd.merge(dfs[0],dfs[1],how=\"outer\", on=[\"Latitude\", \"Longtitude\"])\n",
    "for df in dfs[2:]:\n",
    "    df_1=pd.merge(df_0,df,how=\"outer\", on=[\"Latitude\", \"Longtitude\"])\n",
    "    df_0=df_1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Latitude</th>\n",
       "      <th>Longtitude</th>\n",
       "      <th>res_count</th>\n",
       "      <th>neutron_count</th>\n",
       "      <th>dens_count</th>\n",
       "      <th>densp_count</th>\n",
       "      <th>gr_count</th>\n",
       "      <th>pe_count</th>\n",
       "      <th>compr_count</th>\n",
       "      <th>shear_count</th>\n",
       "      <th>calip_count</th>\n",
       "      <th>denscorr_count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>4.409538</td>\n",
       "      <td>1.957873</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.936264</td>\n",
       "      <td>7.993787</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>5.979132</td>\n",
       "      <td>4.182920</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.887905</td>\n",
       "      <td>8.017887</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2.565869</td>\n",
       "      <td>8.097015</td>\n",
       "      <td>2.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>228</th>\n",
       "      <td>3.194788</td>\n",
       "      <td>7.462122</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>229</th>\n",
       "      <td>3.933811</td>\n",
       "      <td>4.685115</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>230</th>\n",
       "      <td>4.028449</td>\n",
       "      <td>1.562470</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>231</th>\n",
       "      <td>5.619905</td>\n",
       "      <td>4.511351</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>232</th>\n",
       "      <td>5.646275</td>\n",
       "      <td>4.499251</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>233 rows × 12 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     Latitude  Longtitude  res_count  neutron_count  dens_count  densp_count  \\\n",
       "0    4.409538    1.957873        4.0            1.0         1.0          1.0   \n",
       "1    1.936264    7.993787        3.0            1.0         2.0          2.0   \n",
       "2    5.979132    4.182920        2.0            1.0         1.0          1.0   \n",
       "3    1.887905    8.017887        2.0            2.0         3.0          3.0   \n",
       "4    2.565869    8.097015        2.0            NaN         NaN          NaN   \n",
       "..        ...         ...        ...            ...         ...          ...   \n",
       "228  3.194788    7.462122        NaN            NaN         NaN          NaN   \n",
       "229  3.933811    4.685115        NaN            NaN         NaN          NaN   \n",
       "230  4.028449    1.562470        NaN            NaN         NaN          NaN   \n",
       "231  5.619905    4.511351        NaN            NaN         NaN          NaN   \n",
       "232  5.646275    4.499251        NaN            NaN         NaN          NaN   \n",
       "\n",
       "     gr_count  pe_count  compr_count  shear_count  calip_count  denscorr_count  \n",
       "0         1.0       1.0          2.0            1          2.0             1.0  \n",
       "1         2.0       2.0          1.0            1          2.0             2.0  \n",
       "2         1.0       1.0          1.0            1          1.0             1.0  \n",
       "3         2.0       3.0          1.0            1          3.0             3.0  \n",
       "4         1.0       NaN          1.0            1          1.0             NaN  \n",
       "..        ...       ...          ...          ...          ...             ...  \n",
       "228       1.0       NaN          2.0            1          NaN             NaN  \n",
       "229       1.0       NaN          1.0            1          NaN             NaN  \n",
       "230       1.0       NaN          1.0            1          NaN             NaN  \n",
       "231       NaN       NaN          2.0            1          NaN             NaN  \n",
       "232       NaN       NaN          1.0            1          NaN             NaN  \n",
       "\n",
       "[233 rows x 12 columns]"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Latitude</th>\n",
       "      <th>Longtitude</th>\n",
       "      <th>res_count</th>\n",
       "      <th>neutron_count</th>\n",
       "      <th>dens_count</th>\n",
       "      <th>densp_count</th>\n",
       "      <th>gr_count</th>\n",
       "      <th>pe_count</th>\n",
       "      <th>compr_count</th>\n",
       "      <th>shear_count</th>\n",
       "      <th>calip_count</th>\n",
       "      <th>denscorr_count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>233.000000</td>\n",
       "      <td>233.000000</td>\n",
       "      <td>171.000000</td>\n",
       "      <td>200.000000</td>\n",
       "      <td>159.000000</td>\n",
       "      <td>167.000000</td>\n",
       "      <td>227.000000</td>\n",
       "      <td>160.000000</td>\n",
       "      <td>229.000000</td>\n",
       "      <td>233.000000</td>\n",
       "      <td>186.000000</td>\n",
       "      <td>164.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>3.677477</td>\n",
       "      <td>5.900734</td>\n",
       "      <td>1.140351</td>\n",
       "      <td>1.040000</td>\n",
       "      <td>1.088050</td>\n",
       "      <td>1.077844</td>\n",
       "      <td>1.079295</td>\n",
       "      <td>1.087500</td>\n",
       "      <td>1.157205</td>\n",
       "      <td>1.004292</td>\n",
       "      <td>1.118280</td>\n",
       "      <td>1.079268</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>1.873927</td>\n",
       "      <td>2.195399</td>\n",
       "      <td>0.410391</td>\n",
       "      <td>0.196451</td>\n",
       "      <td>0.305719</td>\n",
       "      <td>0.290285</td>\n",
       "      <td>0.301711</td>\n",
       "      <td>0.304835</td>\n",
       "      <td>0.388094</td>\n",
       "      <td>0.065512</td>\n",
       "      <td>0.355633</td>\n",
       "      <td>0.292750</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.594357</td>\n",
       "      <td>1.260153</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>2.254120</td>\n",
       "      <td>3.994768</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>2.980969</td>\n",
       "      <td>6.372655</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>5.709014</td>\n",
       "      <td>7.946482</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>7.421619</td>\n",
       "      <td>9.844046</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>3.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         Latitude  Longtitude   res_count  neutron_count  dens_count  \\\n",
       "count  233.000000  233.000000  171.000000     200.000000  159.000000   \n",
       "mean     3.677477    5.900734    1.140351       1.040000    1.088050   \n",
       "std      1.873927    2.195399    0.410391       0.196451    0.305719   \n",
       "min      0.594357    1.260153    1.000000       1.000000    1.000000   \n",
       "25%      2.254120    3.994768    1.000000       1.000000    1.000000   \n",
       "50%      2.980969    6.372655    1.000000       1.000000    1.000000   \n",
       "75%      5.709014    7.946482    1.000000       1.000000    1.000000   \n",
       "max      7.421619    9.844046    4.000000       2.000000    3.000000   \n",
       "\n",
       "       densp_count    gr_count    pe_count  compr_count  shear_count  \\\n",
       "count   167.000000  227.000000  160.000000   229.000000   233.000000   \n",
       "mean      1.077844    1.079295    1.087500     1.157205     1.004292   \n",
       "std       0.290285    0.301711    0.304835     0.388094     0.065512   \n",
       "min       1.000000    1.000000    1.000000     1.000000     1.000000   \n",
       "25%       1.000000    1.000000    1.000000     1.000000     1.000000   \n",
       "50%       1.000000    1.000000    1.000000     1.000000     1.000000   \n",
       "75%       1.000000    1.000000    1.000000     1.000000     1.000000   \n",
       "max       3.000000    3.000000    3.000000     3.000000     2.000000   \n",
       "\n",
       "       calip_count  denscorr_count  \n",
       "count   186.000000      164.000000  \n",
       "mean      1.118280        1.079268  \n",
       "std       0.355633        0.292750  \n",
       "min       1.000000        1.000000  \n",
       "25%       1.000000        1.000000  \n",
       "50%       1.000000        1.000000  \n",
       "75%       1.000000        1.000000  \n",
       "max       3.000000        3.000000  "
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_1.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_logs=pd.merge(df_1,df_cord,how=\"outer\", on=[\"Latitude\", \"Longtitude\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.chdir(\"C:/Users/Jamal/Downloads/ML SPE competition-take home\")\n",
    "final_logs.to_csv('log inventory-techlog.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "features=['Well name','DEPT',\n",
    "          'AE90','AF90','AHT90', 'AO90', 'AST90','AT90', 'HLLD','IDPH','ILD','LLD', 'RILD', 'RLA5','TBIT90',\n",
    "'APLCLS','APLC_LS','CNC_LS','CNPOR_LS','TNPH_LIM','TNPH_LS','SNP','NPOR','NPORLS','NPOR_LS',\n",
    "'NPHI_LS','NPHILS','NPHI','TNPH',\n",
    "'DPHI','DPHILS','DPHI_LS','DPHI_SLDT','DPHZ','DPHZLS','DPHZ_LS','DPO','DPOR','DPOR_LS', 'DPO_LS','PHND_LS','PORZ_LS',\n",
    "'NRHO','RHOB','RHOB_SLDT','RHOZ','ZDEN', 'RHOM',\n",
    "'ECGR','ECGRD', 'ECGREDTC', 'ECGRR', 'ECGRS', 'GR', 'GRC', 'GRD', 'GRD1','GRN', 'GRR', 'GRS', 'GR_EDTC', 'HCGR',\n",
    "'HSGR', 'HSGRD','HSGRS', 'SGRDD','SGRS',\n",
    "'PE','PEF','PEFL','PEFZ','PEF_SLDT',    \n",
    "'DTCO', 'DTLF', 'DT','DT4P','DTSM','DTCM',\n",
    "'CAL1R', 'CALD', 'CALI', 'CALI_SPCS', 'CALR', 'CALS', 'CALSR', 'CALSR_R', 'CALX', 'HCAL', 'HCALD', 'HCALR','HCALS',\n",
    "'LCAL', 'LCALD', 'LCALR', 'C1','C1S',\n",
    "'HDRA','DRHO','DRH','ZCOR','DCOR','CORR']\n",
    "\n",
    "df_features=df_wells[features]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Obtain dataset code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-32-b5ecf788f51d>:2: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df[df.loc[:]==-9999]=np.nan\n",
      "C:\\Users\\Jamal\\anaconda3\\lib\\site-packages\\pandas\\core\\frame.py:3089: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  self._where(-key, value, inplace=True)\n"
     ]
    }
   ],
   "source": [
    "df=df_features\n",
    "df[df.loc[:]==-9999]=np.nan"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dataset with only shear values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-33-cd68f9e12b82>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mdf_shear\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mdf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mloc\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mdf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mloc\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mpd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnotna\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdf\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'DTSM'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m:\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mindex\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[0mdf_shear\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'DTSM'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0misnull\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msum\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\core\\indexing.py\u001b[0m in \u001b[0;36m__getitem__\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m    877\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    878\u001b[0m             \u001b[0mmaybe_callable\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcom\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mapply_if_callable\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mobj\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 879\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_getitem_axis\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmaybe_callable\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0maxis\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    880\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    881\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_is_scalar_access\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkey\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mTuple\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\core\\indexing.py\u001b[0m in \u001b[0;36m_getitem_axis\u001b[1;34m(self, key, axis)\u001b[0m\n\u001b[0;32m   1097\u001b[0m                     \u001b[1;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"Cannot index with multidimensional key\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1098\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1099\u001b[1;33m                 \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_getitem_iterable\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0maxis\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1100\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1101\u001b[0m             \u001b[1;31m# nested tuple slicing\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\core\\indexing.py\u001b[0m in \u001b[0;36m_getitem_iterable\u001b[1;34m(self, key, axis)\u001b[0m\n\u001b[0;32m   1035\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1036\u001b[0m         \u001b[1;31m# A collection of keys\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1037\u001b[1;33m         \u001b[0mkeyarr\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mindexer\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_get_listlike_indexer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mraise_missing\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1038\u001b[0m         return self.obj._reindex_with_indexers(\n\u001b[0;32m   1039\u001b[0m             \u001b[1;33m{\u001b[0m\u001b[0maxis\u001b[0m\u001b[1;33m:\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mkeyarr\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mindexer\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mallow_dups\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\core\\indexing.py\u001b[0m in \u001b[0;36m_get_listlike_indexer\u001b[1;34m(self, key, axis, raise_missing)\u001b[0m\n\u001b[0;32m   1250\u001b[0m             \u001b[0mkeyarr\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0max\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mreindex\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkeyarr\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1251\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1252\u001b[1;33m             \u001b[0mkeyarr\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mindexer\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnew_indexer\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0max\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_reindex_non_unique\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkeyarr\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1253\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1254\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_validate_read_indexer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkeyarr\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mindexer\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mraise_missing\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mraise_missing\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\core\\indexes\\base.py\u001b[0m in \u001b[0;36m_reindex_non_unique\u001b[1;34m(self, target)\u001b[0m\n\u001b[0;32m   3367\u001b[0m         \"\"\"\n\u001b[0;32m   3368\u001b[0m         \u001b[0mtarget\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mensure_index\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtarget\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 3369\u001b[1;33m         \u001b[0mindexer\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmissing\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_indexer_non_unique\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtarget\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   3370\u001b[0m         \u001b[0mcheck\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mindexer\u001b[0m \u001b[1;33m!=\u001b[0m \u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3371\u001b[0m         \u001b[0mnew_labels\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtake\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mindexer\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mcheck\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\core\\indexes\\base.py\u001b[0m in \u001b[0;36mget_indexer_non_unique\u001b[1;34m(self, target)\u001b[0m\n\u001b[0;32m   4695\u001b[0m             \u001b[0mtgt_values\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtarget\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_get_engine_target\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   4696\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 4697\u001b[1;33m         \u001b[0mindexer\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmissing\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_engine\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_indexer_non_unique\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtgt_values\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   4698\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mensure_platform_int\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mindexer\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmissing\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   4699\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mpandas\\_libs\\index.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_indexer_non_unique\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32m<__array_function__ internals>\u001b[0m in \u001b[0;36mresize\u001b[1;34m(*args, **kwargs)\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\numpy\\core\\fromnumeric.py\u001b[0m in \u001b[0;36mresize\u001b[1;34m(a, new_shape)\u001b[0m\n\u001b[0;32m   1415\u001b[0m         \u001b[0mextra\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mNa\u001b[0m \u001b[1;33m-\u001b[0m \u001b[0mextra\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1416\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1417\u001b[1;33m     \u001b[0ma\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mconcatenate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0ma\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m*\u001b[0m \u001b[0mn_copies\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1418\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mextra\u001b[0m \u001b[1;33m>\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1419\u001b[0m         \u001b[0ma\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0ma\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m-\u001b[0m\u001b[0mextra\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<__array_function__ internals>\u001b[0m in \u001b[0;36mconcatenate\u001b[1;34m(*args, **kwargs)\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "df_shear=df.loc[df.loc[pd.notna(df['DTSM']), :].index]\n",
    "df_shear['DTSM'].isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Curves for each well"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "neutron_df=df_curves[(df_curves['Mnemonic']=='NPHI') | (df_curves['Mnemonic']=='NPOR')| (df_curves['Mnemonic']=='TNPH')]\n",
    "neutron_df_remove=neutron_df[(neutron_df['Description']!='NEUTRON POROSITY LIMESTONE') \n",
    "                             & (neutron_df['Description']!='THERMAL NEUTRON POROSITY LIMESTONE')]\n",
    "df_curves.drop(neutron_df_remove.index,axis=0,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "densitypor_df=df_curves[(df_curves['Mnemonic']=='DPHI') | (df_curves['Mnemonic']=='DPHZ')]\n",
    "densitypor_df_remove=densitypor_df[(densitypor_df['Description']!='DENSITY POROSITY LIMESTONE')]\n",
    "df_curves.drop(densitypor_df_remove.index,axis=0,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_replace=final_logs\n",
    "df_curves_replace=df_curves[df_curves['Well name'].isin(df_replace['Well name'])]\n",
    "df_curves_replace=df_curves_replace[df_curves_replace['Mnemonic'].isin(df_shear.columns[1:])]\n",
    "df_curves_replace"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Function to combine the curves"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def replace(curve,property_curves):\n",
    "    \n",
    "    mnemonic_0=df_curves_replace.loc[df_curves_replace['Mnemonic'].isin(property_curves)]['Mnemonic'].unique()\n",
    "    mnemonic=np.append(mnemonic_0,'Well name')\n",
    "    mnemonic=np.append(mnemonic,'DEPT')\n",
    "    #wname=df_curves_replace.loc[mnemonic_0]['Well name']\n",
    "    wname=df_curves_replace.loc[df_curves_replace.loc[df_curves_replace['Mnemonic'].isin(property_curves)]['Mnemonic'].index][\"Well name\"].unique()\n",
    "    \n",
    "    df_replace=df_shear[df_shear['Well name'].isin(wname)]\n",
    "    df_f=df_replace[mnemonic]\n",
    "    \n",
    "    df_f.dropna(how='all',subset=mnemonic_0,inplace=True)\n",
    "    \n",
    "    stat=df_f.isnull().sum(axis=1)\n",
    "    stat_index=stat[stat<len(mnemonic_0)-1].index\n",
    "    \n",
    "    index_df = df_f.index.isin(stat_index)\n",
    "    \n",
    "    df_f.fillna(0,inplace=True)\n",
    "    \n",
    "    df_f[curve]=\"\"\n",
    "    \n",
    "    df_dup=df_f[mnemonic_0].loc[index_df]\n",
    "    df_ndup=df_f[mnemonic_0].loc[~index_df]\n",
    "    \n",
    "    df_f[curve].loc[index_df]=df_dup[df_dup!=0].mean(axis=1)\n",
    "    \n",
    "    df_f[curve].loc[~index_df]=df_ndup.sum(axis=1)\n",
    "    \n",
    "    \n",
    "    return df_f"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "res_curves=['AE90','AF90','AHT90', 'AO90', 'AST90','AT90', 'HLLD','IDPH','ILD','LLD','LLD_R', 'RILD', 'RLA5','TBIT90']\n",
    "gr_curves=['ECGR','ECGRD', 'ECGREDTC', 'ECGRR', 'ECGRS', 'GR', 'GRC', 'GRD', 'GRD1','GRN', 'GRR', 'GRS', 'GRT', \n",
    "           'GR_EDTC', 'GR_STGC','HCGR','HCGRD', 'HSGR', 'HSGRD', 'HSGRR','HSGRS', 'SGRDD','SGRS']\n",
    "calp_curves=['CAL1R', 'CALD', 'CALI', 'CALI_SPCS', 'CALR', 'CALS', 'CALSR', 'CALSR_R', 'CALX', 'HCAL', 'HCALD', 'HCALR','HCALS',\n",
    "'HD', 'HD1', 'LCAL', 'LCALD', 'LCALR', 'C1','C1S']\n",
    "pe_curves=['PE','PEF','PEFL','PEFZ','PEF_SLDT']\n",
    "dens_curves=['NRHO','RHOB','RHOB_SLDT','RHOZ','ZDEN', 'RHOM']\n",
    "neut_curves=['APLCLS','APLC_LS','CNC', 'CNC_LS','CNPOR_LS','TNPH_LIM','TNPH_LS','TPHI_LS','SNP','NPOR','NPORLS','NPOR_LS',\n",
    "             'NPHS','NPHI_LS','NPHILS','NPHI', 'ENPH_LS','TNPH']\n",
    "densp_curves=['DPHI','DPHILS','DPHI_LS','DPHI_SLDT','DPHZ','DPHZLS','DPHZ_LS','DPO','DPOR','DPOR_LS', 'DPO_LS','PHND_LS','PORZ_LS']\n",
    "comp_curves=['DTCO', 'DTLF', 'DT','DT4P','DTCM']\n",
    "shear_curves=['DTSM']\n",
    "denscorr_curves=['HDRA','DRHO','DRH']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "curves=[res_curves,gr_curves,calp_curves,pe_curves,dens_curves,denscorr_curves,neut_curves,densp_curves,comp_curves,\n",
    "        shear_curves]\n",
    "properties=['Resistivity','Gamma ray','Caliper','Photoelectric','Density','Density correction','Neutron porosity',\n",
    "            'Density porosity','Compressional slowness','Shear slowness']\n",
    "\n",
    "df_prop_0=replace(properties[0],curves[0])\n",
    "\n",
    "for i in range(1,len(curves)):\n",
    "    \n",
    "    df_prop=replace(properties[i],curves[i])\n",
    "    df_prop=df_prop.merge(df_prop_0,how='outer')\n",
    "    df_prop_0=df_prop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_props=properties\n",
    "final_props.append('DEPT')\n",
    "final_props.append('Well name')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df=df_prop[final_props]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Before cleaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.hist(bins=25,figsize=(15,20))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.skew()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def corr_matrix(dataframe):\n",
    "    matrix=dataframe.corr(method='spearman')\n",
    "    return matrix.round(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "corr_matrix(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cleaning process"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_outliers_index(property,lower_quant,upper_quant):\n",
    "    if lower_quant>0 and upper_quant>0:\n",
    "        dat=df[property]\n",
    "        P_uq=dat.quantile(upper_quant)\n",
    "        P_lq=dat.quantile(lower_quant)\n",
    "        index = df[(dat >= P_uq)|(dat<=P_lq)].index\n",
    "    elif lower_quant>0 and upper_quant==0:\n",
    "        dat=df[property]\n",
    "        P_lq=dat.quantile(lower_quant)\n",
    "        index = df[dat<=P_lq].index\n",
    "    else:\n",
    "        dat=df[property]\n",
    "        P_uq=dat.quantile(upper_quant)\n",
    "        index = df[dat >= P_uq].index\n",
    "    return index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_outliers_df(df_out):\n",
    "    \n",
    "    uq=0.99\n",
    "    lq=0.01\n",
    "\n",
    "    df_out.loc[remove_outliers_index('Gamma ray',lq,0.998),'Gamma ray']=np.nan #GR's corr was improved\n",
    "    df_out.loc[remove_outliers_index('Density',0.008,uq),'Density']=np.nan\n",
    "    df_out.loc[remove_outliers_index('Neutron porosity',0.005,0.993),'Neutron porosity']=np.nan \n",
    "    df_out.loc[remove_outliers_index('Compressional slowness',0.008,0.998),'Compressional slowness']=np.nan\n",
    "    df_out.loc[remove_outliers_index('Resistivity',0.005,0.995),'Resistivity']=np.nan\n",
    "    df_out.loc[remove_outliers_index('Photoelectric',0.005,0.998),'Photoelectric']=np.nan\n",
    "    df_out.loc[remove_outliers_index('Density porosity',lq,0.995),'Density porosity']=np.nan\n",
    "    df_out.loc[remove_outliers_index('Shear slowness',0.008,0.998),'Shear slowness']=np.nan\n",
    "    df_out.loc[remove_outliers_index('Caliper',lq,0.97),'Caliper']=np.nan\n",
    "\n",
    "    return df_out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_outlier=df\n",
    "df5=remove_outliers_df(df_outlier)\n",
    "df5.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df5.hist(bins=25,figsize=(15,20))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "corr_matrix(df5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Density filter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df5_denscorr=df5\n",
    "index_denscorr=df5_denscorr[(df5_denscorr['Density correction']>0.2) | (df5_denscorr['Density correction']<-0.2)].index\n",
    "df5_denscorr.loc[index_denscorr,'Density correction']=np.nan\n",
    "df5_denscorr.loc[index_denscorr,'Density']=np.nan\n",
    "df5_denscorr.loc[index_denscorr,'Photoelectric']=np.nan\n",
    "df5_denscorr.loc[index_denscorr,'Caliper']=np.nan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df5_denscorr.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "plt.figure(figsize=(9,7))\n",
    "sns.heatmap(corr_matrix(df5_denscorr),annot=True,cmap=plt.cm.Reds,)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df5_denscorr_cord=df5_denscorr.merge(df_cord,on='Well name')\n",
    "df5_denscorr_cord"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Depth intervals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def div_interval(df5_denscorr):\n",
    "    \n",
    "    df5_depth1=df5_denscorr[(df5_denscorr['DEPT']>=586) & (df5_denscorr['DEPT']<=6615)]\n",
    "    df5_depth2=df5_denscorr[(df5_denscorr['DEPT']>6615) & (df5_denscorr['DEPT']<=9153)]\n",
    "    df5_depth3=df5_denscorr[(df5_denscorr['DEPT']>9153) & (df5_denscorr['DEPT']<=12506)]\n",
    "    df5_depth4=df5_denscorr[(df5_denscorr['DEPT']>12506)]\n",
    "    \n",
    "    return df5_depth1,df5_depth2,df5_depth3,df5_depth4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df5_depth1,df5_depth2,df5_depth3,df5_depth4=div_interval(df5_denscorr_cord)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def strat_split(df_f,test,prop):\n",
    "    \n",
    "    cat=prop+\"_cat\"\n",
    "    \n",
    "    df_f.drop(['Well name'],axis=1,inplace=True)\n",
    "    df_f[cat] = pd.cut(df_f[prop],bins=[64,100,114, 136, np.inf],labels=[1, 2, 3, 4])\n",
    "    df_f=df_f.astype('float64')\n",
    "    df_f.reset_index(drop=True,inplace=True)\n",
    "    \n",
    "    train_set, test_set = train_test_split(df_f, test_size=test, random_state=42)\n",
    "    \n",
    "    train_set=train_set.drop([cat],axis=1)\n",
    "    test_set=test_set.drop([cat],axis=1)\n",
    "    \n",
    "    return train_set, test_set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "depth_intervals=[df5_depth1,df5_depth2,df5_depth3,df5_depth4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def export(df_input,depth_no):\n",
    "    \n",
    "    df_final = df_input.sample(frac=1,random_state=42).reset_index(drop=True)\n",
    "    \n",
    "    train_set, test_set=train_test_split(df_final, test_size=0.2, random_state=42)\n",
    "    train_set.to_csv('Train set depth '+str(depth_no)+'.csv')\n",
    "    test_set.to_csv('Test set depth '+str(depth_no)+'.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "i=0\n",
    "for depth_interval in depth_intervals:\n",
    "    i=i+1\n",
    "    export(depth_interval,i)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model runs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sklearn\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import os\n",
    "import glob\n",
    "import seaborn as sns\n",
    "from sklearn.model_selection import StratifiedShuffleSplit\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import r2_score\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.linear_model import Ridge\n",
    "from sklearn.linear_model import Lasso\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.svm import SVR\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "import joblib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cross_val(model_name,model_input,X_train_scaled, y_train):\n",
    "    \n",
    "    model=model_input\n",
    "    \n",
    "    #Whole training dataset\n",
    "    model.fit(X_train_scaled, y_train)\n",
    "    predictions = model.predict(X_train_scaled)\n",
    "    mse = mean_squared_error(y_train, predictions)\n",
    "    rmse = np.sqrt(mse)\n",
    "    graph=plt.scatter(y_train, predictions)\n",
    "    \n",
    "    #Cross-validation\n",
    "    scores = cross_val_score(model, X_train_scaled, y_train,scoring=\"neg_mean_squared_error\", cv=10)\n",
    "    rmse_scores = np.sqrt(-scores)\n",
    "    \n",
    "    r_squared=r2_score(y_train,predictions)\n",
    "    \n",
    "    import joblib\n",
    "    joblib.dump(model, model_name)\n",
    "    \n",
    "    print('R2:',r_squared)\n",
    "    print(\"RMSE on whole training set:\", rmse)\n",
    "    print(\"Scores:\", rmse_scores)\n",
    "    print(\"Mean:\", rmse_scores.mean())\n",
    "    print(\"Standard deviation:\", rmse_scores.std())\n",
    "    \n",
    "    \n",
    "    return graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_model(model,train_set,test_set,depth_no):\n",
    "    \n",
    "    X_train=train_set[features[:-1]]\n",
    "    X_train.loc[:,'Resistivity']=np.log10(X_train['Resistivity'])\n",
    "    X_test=test_set[features[:-1]]\n",
    "    X_test.loc[:,'Resistivity']=np.log10(X_test['Resistivity'])\n",
    "    y_train=train_set[features[-1]]\n",
    "    y_test=test_set[features[-1]]\n",
    "    \n",
    "    from sklearn.preprocessing import MinMaxScaler, StandardScaler\n",
    "    scaler=MinMaxScaler()\n",
    "    X_train_scaled=pd.DataFrame(scaler.fit_transform(X_train))\n",
    "    X_test_scaled=pd.DataFrame(scaler.fit_transform(X_test))\n",
    "    \n",
    "    from sklearn.neighbors import KNeighborsRegressor\n",
    "    knn_reg=KNeighborsRegressor(n_neighbors=5)\n",
    "    cross_val(model+str(depth_no),knn_reg,X_train_scaled,y_train)\n",
    "    \n",
    "    return depth_no"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def model_save(features,model):\n",
    "    \n",
    "    train_set_depth1=pd.read_csv('Train set depth 1.csv',index_col=False)\n",
    "    train_set_depth1.drop('Unnamed: 0',axis=1,inplace=True)\n",
    "    train_set_depth1.dropna(subset=features,inplace=True)\n",
    "\n",
    "    test_set_depth1=pd.read_csv('Test set depth 1.csv',index_col=False)\n",
    "    test_set_depth1.drop('Unnamed: 0',axis=1,inplace=True)\n",
    "    test_set_depth1.dropna(subset=features,inplace=True)\n",
    "\n",
    "    train_set_depth2=pd.read_csv('Train set depth 2.csv',index_col=False)\n",
    "    train_set_depth2.drop('Unnamed: 0',axis=1,inplace=True)\n",
    "    train_set_depth2.dropna(subset=features,inplace=True)\n",
    "\n",
    "    test_set_depth2=pd.read_csv('Test set depth 2.csv',index_col=False)\n",
    "    test_set_depth2.drop('Unnamed: 0',axis=1,inplace=True)\n",
    "    test_set_depth2.dropna(subset=features,inplace=True)\n",
    "\n",
    "    train_set_depth3=pd.read_csv('Train set depth 3.csv',index_col=False)\n",
    "    train_set_depth3.drop('Unnamed: 0',axis=1,inplace=True)\n",
    "    train_set_depth3.dropna(subset=features,inplace=True)\n",
    "\n",
    "    test_set_depth3=pd.read_csv('Test set depth 3.csv',index_col=False)\n",
    "    test_set_depth3.drop('Unnamed: 0',axis=1,inplace=True)\n",
    "    test_set_depth3.dropna(subset=features,inplace=True)\n",
    "\n",
    "    train_set_depth4=pd.read_csv('Train set depth 4.csv',index_col=False)\n",
    "    train_set_depth4.drop('Unnamed: 0',axis=1,inplace=True)\n",
    "    train_set_depth4.dropna(subset=features,inplace=True)\n",
    "\n",
    "    test_set_depth4=pd.read_csv('Test set depth 4.csv',index_col=False)\n",
    "    test_set_depth4.drop('Unnamed: 0',axis=1,inplace=True)\n",
    "    test_set_depth4.dropna(subset=features,inplace=True)\n",
    "\n",
    "    train_sets=[train_set_depth1,train_set_depth2,train_set_depth3,train_set_depth4]\n",
    "    test_sets=[test_set_depth1,test_set_depth2,test_set_depth3,test_set_depth4]\n",
    "\n",
    "    for i in range(len(train_sets)):\n",
    "\n",
    "        run_model(model,train_sets[i],test_sets[i],i+1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "features1=['Resistivity','Gamma ray', 'Density', 'Neutron porosity', 'Compressional slowness', 'Shear slowness']\n",
    "features2=['Resistivity','Gamma ray', 'Density', 'Compressional slowness', 'Shear slowness']\n",
    "features3=['Resistivity','Gamma ray', 'Neutron porosity', 'Compressional slowness', 'Shear slowness']\n",
    "features4=['Resistivity','Gamma ray', 'Compressional slowness', 'Shear slowness']\n",
    "features5=['Gamma ray', 'Neutron porosity','Density', 'Compressional slowness', 'Shear slowness']\n",
    "features6=['Compressional slowness', 'Shear slowness']\n",
    "features_all=[features1,features2,features3,features4,features5,features6]\n",
    "models_all=['knn_reg','knn_reg_cdgr','knn_reg_cngr','knn_reg_cgr','knn_reg_cgnd','knn_reg_comp']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(len(features_all)):\n",
    "\n",
    "        model_save(features_all[i],models_all[i])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Prediction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Obtain dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Change directory\n",
    "os.chdir(\"C:/Users/Jamal/Downloads/ML SPE competition-take home/Final submission\")\n",
    "# Create a list with all the files\n",
    "path = os.getcwd()\n",
    "files = os.listdir(path)\n",
    "# Select only xlsx files\n",
    "files_las = [f for f in files if f[-3:] == \"las\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lst=[]\n",
    "lst2=[]\n",
    "\n",
    "# Loop over list of Excel files\n",
    "for f in files_las: \n",
    "    las=lasio.read(f)\n",
    "    df=las.df()\n",
    "    df.reset_index(inplace=True)\n",
    "    lst.append(df)\n",
    "    \n",
    "    well_name = pd.DataFrame([f] * df.shape[0])\n",
    "    lst2.append(well_name)\n",
    "    \n",
    "df2=pd.concat(lst,axis=0)\n",
    "df_names=pd.concat(lst2,axis=0)\n",
    "\n",
    "df_wells=pd.concat([df2,df_names],axis=1)\n",
    "df_wells.rename(columns={0:\"Well name\"},inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Lat=[]\n",
    "\n",
    "# Loop over list of Excel files\n",
    "for f in files_las:\n",
    "    \n",
    "    las=lasio.read(f)\n",
    "    Lat.append({'Latitude':las.well['SLAT'].value,'Longtitude':las.well['SLON'].value,'Well name':f})\n",
    "\n",
    "df_cord=pd.DataFrame(Lat)\n",
    "df_cord"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clmn=df2.columns\n",
    "clmn_df=pd.DataFrame(clmn)\n",
    "clmn_df.columns=['Property']\n",
    "clmn_df.sort_values('Property',inplace=True)\n",
    "clmn_df.reset_index(drop=True,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "logs=[]\n",
    "a_list = []\n",
    "b_list = []\n",
    "c_list = []\n",
    "Lat=[]\n",
    "Lon=[]\n",
    "w_list=[]\n",
    "\n",
    "for f in files_las: \n",
    "    las=lasio.read(f)\n",
    "    colnum=las.keys()\n",
    "    logs=las.curves\n",
    "    for i in range(0,len(colnum)):\n",
    "        a=logs[i]['descr']\n",
    "        a_list.append(a)\n",
    "        b=logs[i]['unit']\n",
    "        b_list.append(b)\n",
    "        c=logs[i]['mnemonic']\n",
    "        c_list.append(c)\n",
    "        Lat.append(las.well['SLAT'].value)\n",
    "        Lon.append(las.well['SLON'].value)\n",
    "        w_list.append(f)\n",
    "\n",
    "df_curves = pd.DataFrame({'Mnemonic': c_list, 'Unit': b_list,'Description': a_list,'Latitude': Lat,'Longtitude': Lon,\n",
    "                               'Well name': w_list})\n",
    "df_curves"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def log_count(df,name):\n",
    "    prop=df.groupby(['Latitude', 'Longtitude']).size().rename(name+'_count').sort_values(ascending=False)\n",
    "    df_f=pd.DataFrame(prop).reset_index()\n",
    "    return df_f"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "comp_df_res=df_curves[(df_curves['Mnemonic']=='AE90') | (df_curves['Mnemonic']=='AF90') | (df_curves['Mnemonic']=='AHT90') \n",
    "                 | (df_curves['Mnemonic']=='AO90') | (df_curves['Mnemonic']=='AST90') | (df_curves['Mnemonic']=='AT90')\n",
    "                 | (df_curves['Mnemonic']=='HLLD') | (df_curves['Mnemonic']=='HRID') | (df_curves['Mnemonic']=='IDPH')\n",
    "                 | (df_curves['Mnemonic']=='ILD')| (df_curves['Mnemonic']=='LLD') | (df_curves['Mnemonic']=='LLD_R')\n",
    "                 | (df_curves['Mnemonic']=='RILD') | (df_curves['Mnemonic']=='RLA5') | (df_curves['Mnemonic']=='TBIT90')\n",
    "                 | (df_curves['Mnemonic']=='HLLD1')]\n",
    "comp_df_neut=df_curves[(df_curves['Mnemonic']=='APLCLS') | (df_curves['Mnemonic']=='APLC_LS') | (df_curves['Mnemonic']=='CNC') \n",
    "                 | (df_curves['Mnemonic']=='CNC_LS') | (df_curves['Mnemonic']=='CNPOR_LS') | (df_curves['Mnemonic']=='TNPH_LIM')\n",
    "                 | (df_curves['Mnemonic']=='TNPH_LS') | (df_curves['Mnemonic']=='TPHI_LS') | (df_curves['Mnemonic']=='SNP')\n",
    "                 | (df_curves['Mnemonic']=='NPOR')| (df_curves['Mnemonic']=='NPORLS') | (df_curves['Mnemonic']=='NPOR_LS')\n",
    "                 | (df_curves['Mnemonic']=='NPHS') | (df_curves['Mnemonic']=='NPHI_LS') | (df_curves['Mnemonic']=='NPHILS')\n",
    "                | (df_curves['Mnemonic']=='NPHI') | (df_curves['Mnemonic']=='ENPH_LS')| (df_curves['Mnemonic']=='TNPH')]\n",
    "comp_df_densp=df_curves[(df_curves['Mnemonic']=='DPHI') | (df_curves['Mnemonic']=='DPHILS') | (df_curves['Mnemonic']=='DPHI_LS') \n",
    "                 | (df_curves['Mnemonic']=='DPHI_SLDT') | (df_curves['Mnemonic']=='DPHZ') | (df_curves['Mnemonic']=='DPHZLS')\n",
    "                 | (df_curves['Mnemonic']=='DPHZ_LS') | (df_curves['Mnemonic']=='DPO') | (df_curves['Mnemonic']=='DPOR')\n",
    "                 | (df_curves['Mnemonic']=='DPOR_LS')| (df_curves['Mnemonic']=='DPO_LS') | (df_curves['Mnemonic']=='PHND_LS')\n",
    "                 | (df_curves['Mnemonic']=='PORZ_LS')]\n",
    "comp_df_dens=df_curves[(df_curves['Mnemonic']=='NRHO') | (df_curves['Mnemonic']=='RHOB') | (df_curves['Mnemonic']=='RHOB_SLDT') \n",
    "                 | (df_curves['Mnemonic']=='RHOZ') | (df_curves['Mnemonic']=='ZDEN') | (df_curves['Mnemonic']=='RHOM')]\n",
    "comp_df_gr=df_curves[(df_curves['Mnemonic']=='ECGR') | (df_curves['Mnemonic']=='ECGRD') | (df_curves['Mnemonic']=='ECGREDTC') \n",
    "                 | (df_curves['Mnemonic']=='ECGRR') | (df_curves['Mnemonic']=='ECGRS')\n",
    "                | (df_curves['Mnemonic']=='GRC') | (df_curves['Mnemonic']=='GRD') | (df_curves['Mnemonic']=='GRD1')\n",
    "                | (df_curves['Mnemonic']=='GRN') | (df_curves['Mnemonic']=='GRR') | (df_curves['Mnemonic']=='GRS')\n",
    "                | (df_curves['Mnemonic']=='GRT') | (df_curves['Mnemonic']=='GR_EDTC') | (df_curves['Mnemonic']=='GR_STGC')\n",
    "                | (df_curves['Mnemonic']=='HCGR') | (df_curves['Mnemonic']=='HCGRD') | (df_curves['Mnemonic']=='HCGRR')\n",
    "                | (df_curves['Mnemonic']=='HCGRS') | (df_curves['Mnemonic']=='HGRT') | (df_curves['Mnemonic']=='HSGR')\n",
    "                | (df_curves['Mnemonic']=='HSGRD') | (df_curves['Mnemonic']=='HSGRR') | (df_curves['Mnemonic']=='HSGRS')\n",
    "                    | (df_curves['Mnemonic']=='SGRDD') | (df_curves['Mnemonic']=='SGRS')]\n",
    "comp_df_pe=df_curves[(df_curves['Mnemonic']=='PE') | (df_curves['Mnemonic']=='PEF') | (df_curves['Mnemonic']=='PEFL') \n",
    "                 | (df_curves['Mnemonic']=='PEFS') | (df_curves['Mnemonic']=='PEFZ') | (df_curves['Mnemonic']=='PEF_SLDT')]\n",
    "comp_df_compr=df_curves[(df_curves['Mnemonic']=='DTCO')]\n",
    "comp_df_shear=df_curves[(df_curves['Mnemonic']=='DTSM')]\n",
    "comp_df_calip=df_curves[(df_curves['Mnemonic']=='CAL1R') | (df_curves['Mnemonic']=='CALD') | (df_curves['Mnemonic']=='CALI') \n",
    "                 | (df_curves['Mnemonic']=='CALI_SPCS') | (df_curves['Mnemonic']=='CALR') | (df_curves['Mnemonic']=='CALS')\n",
    "                | (df_curves['Mnemonic']=='CALSR') | (df_curves['Mnemonic']=='CALSR_R') | (df_curves['Mnemonic']=='CALX')\n",
    "                | (df_curves['Mnemonic']=='HCAL') | (df_curves['Mnemonic']=='HCALD') | (df_curves['Mnemonic']=='HCALR')\n",
    "               | (df_curves['Mnemonic']=='HCALS') | (df_curves['Mnemonic']=='HD') | (df_curves['Mnemonic']=='HD1')\n",
    "                | (df_curves['Mnemonic']=='LCAL') | (df_curves['Mnemonic']=='LCALD') | (df_curves['Mnemonic']=='LCALR') |\n",
    "                        (df_curves['Mnemonic']=='C1') | (df_curves['Mnemonic']=='C1S') | (df_curves['Mnemonic']=='HCALR_1')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfs=[log_count(comp_df_res,'res'),log_count(comp_df_neut,'neutron'),log_count(comp_df_dens,'dens'),log_count(comp_df_densp,'densp'),\n",
    "         log_count(comp_df_gr,'gr'), log_count(comp_df_pe,'pe'),log_count(comp_df_compr,'compr'),log_count(comp_df_shear,'shear'),\n",
    "         log_count(comp_df_calip,'calip')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_0=pd.merge(dfs[0],dfs[1],how=\"outer\", on=[\"Latitude\", \"Longtitude\"])\n",
    "for df in dfs[2:]:\n",
    "    df_1=pd.merge(df_0,df,how=\"outer\", on=[\"Latitude\", \"Longtitude\"])\n",
    "    df_0=df_1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_logs=pd.merge(df_1,df_cord,how=\"outer\", on=[\"Latitude\", \"Longtitude\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "features=np.concatenate((['Well name','DEPT'],comp_df_res['Mnemonic'].unique(),comp_df_neut['Mnemonic'].unique(),comp_df_densp['Mnemonic'].unique(),\n",
    "                comp_df_dens['Mnemonic'].unique(),comp_df_gr['Mnemonic'].unique(),comp_df_pe['Mnemonic'].unique(),\n",
    "                comp_df_calip['Mnemonic'].unique(),comp_df_compr['Mnemonic'].unique()),axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_features=df_wells[features]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df=df_features\n",
    "df[df.loc[:]==-9999]=np.nan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_replace=final_logs\n",
    "df_curves_replace=df_curves[df_curves['Well name'].isin(df_replace['Well name'])]\n",
    "df_curves_replace=df_curves_replace[df_curves_replace['Mnemonic'].isin(df.columns[1:])]\n",
    "df_curves_replace"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def replace(curve,property_curves):\n",
    "    \n",
    "    \n",
    "    mnemonic_0=df_curves_replace.loc[df_curves_replace['Mnemonic'].isin(property_curves)]['Mnemonic'].unique()\n",
    "    mnemonic=np.append(mnemonic_0,'Well name')\n",
    "    mnemonic=np.append(mnemonic,'DEPT')\n",
    "    #wname=df_curves_replace.loc[mnemonic_0]['Well name']\n",
    "    wname=df_curves_replace.loc[df_curves_replace.loc[df_curves_replace['Mnemonic'].isin(property_curves)]['Mnemonic'].index][\"Well name\"].unique()\n",
    "    \n",
    "    df_replace=df[df['Well name'].isin(wname)]\n",
    "    df_f=df_replace[mnemonic]\n",
    "    \n",
    "    df_f.dropna(how='all',subset=mnemonic_0,inplace=True)\n",
    "    \n",
    "    stat=df_f.isnull().sum(axis=1)\n",
    "    stat_index=stat[stat<len(mnemonic_0)-1].index\n",
    "    \n",
    "    index_df = df_f.index.isin(stat_index)\n",
    "    \n",
    "    df_f.fillna(0,inplace=True)\n",
    "    \n",
    "    df_f[curve]=\"\"\n",
    "    \n",
    "    df_dup=df_f[mnemonic_0].loc[index_df]\n",
    "    df_ndup=df_f[mnemonic_0].loc[~index_df]\n",
    "    \n",
    "    df_f[curve].loc[index_df]=df_dup[df_dup!=0].mean(axis=1)\n",
    "    \n",
    "    df_f[curve].loc[~index_df]=df_ndup.sum(axis=1)\n",
    "    \n",
    "    \n",
    "    return df_f"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "res_curves=['AT90', 'HLLD','IDPH','ILD','LLD','HLLD1']\n",
    "gr_curves=['GRD', 'GRR', 'GRS']\n",
    "calp_curves=['CALR', 'HCALD', 'HCALR','CAL1R', 'CALD', 'CALS', 'CALSR', 'LCALD', 'HCAL','HCALR_1']\n",
    "pe_curves=['PEF','PEFL','PEFZ','PEFS']\n",
    "dens_curves=['RHOB','RHOZ','RHOM']\n",
    "neut_curves=['TNPH_LS','NPOR_LS','NPHI_LS','NPHI']\n",
    "densp_curves=['DPHI_LS','DPHZ_LS', 'DPHZ','DPHI']\n",
    "comp_curves=['DTCO']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "curves=[res_curves,gr_curves,calp_curves,pe_curves,dens_curves,neut_curves,densp_curves,comp_curves]\n",
    "properties=['Resistivity','Gamma ray','Caliper','Photoelectric','Density','Neutron porosity','Density porosity',\n",
    "           'Compressional slowness']\n",
    "\n",
    "df_prop_0=replace(properties[0],curves[0])\n",
    "\n",
    "for i in range(1,len(curves)):\n",
    "    \n",
    "    df_prop=replace(properties[i],curves[i])\n",
    "    df_prop=df_prop.merge(df_prop_0,how='outer')\n",
    "    df_prop_0=df_prop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_props=properties\n",
    "final_props.append('DEPT')\n",
    "final_props.append('Well name')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df=df_prop[final_props]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['Resistivity']=np.log10(df['Resistivity'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df=df.sort_values(['Well name','DEPT'])\n",
    "df.reset_index(drop=True,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def div_interval(df5_denscorr):\n",
    "    \n",
    "    df5_depth1=df5_denscorr[(df5_denscorr['DEPT']>=586) & (df5_denscorr['DEPT']<=6615)]\n",
    "    df5_depth2=df5_denscorr[(df5_denscorr['DEPT']>6615) & (df5_denscorr['DEPT']<=9153)]\n",
    "    df5_depth3=df5_denscorr[(df5_denscorr['DEPT']>9153) & (df5_denscorr['DEPT']<=12506)]\n",
    "    df5_depth4=df5_denscorr[(df5_denscorr['DEPT']>12506)]\n",
    "    \n",
    "    return df5_depth1,df5_depth2,df5_depth3,df5_depth4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df5_depth1,df5_depth2,df5_depth3,df5_depth4=div_interval(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Predictions for Depth interval 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(model_name,X_pred,X_pred_scaled):\n",
    "    \n",
    "    import joblib\n",
    "    loaded_model = joblib.load(model_name)\n",
    "    final_predictions=loaded_model.predict(X_pred_scaled)\n",
    "    X_pred['DTSM']=final_predictions\n",
    "    \n",
    "    return X_pred['DTSM']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df=df5_depth1\n",
    "features=['Resistivity','Gamma ray', 'Density', 'Neutron porosity', 'Compressional slowness']\n",
    "X=df[features]\n",
    "X_pred=X\n",
    "X_pred.dropna(inplace=True)\n",
    "rest_index=df[features].index.isin(X_pred.index)\n",
    "X_rest=df[features][~rest_index]\n",
    "X_neut_res=X_rest.dropna(subset=['Compressional slowness','Gamma ray','Neutron porosity','Resistivity'])\n",
    "X_neut_res=X_neut_res[['Compressional slowness','Gamma ray','Neutron porosity','Resistivity']]\n",
    "X_dens_res=X_rest.dropna(subset=['Compressional slowness','Gamma ray','Density','Resistivity'])\n",
    "X_dens_res=X_dens_res[['Compressional slowness','Gamma ray','Density','Resistivity']]\n",
    "nores_index=df[features].index.isin([*X_dens_res.index,*X_neut_res.index,*X_pred.index])\n",
    "X_nores=df[features][~nores_index]\n",
    "X_cgdn=X_nores.dropna(subset=['Compressional slowness','Gamma ray','Density','Neutron porosity'])\n",
    "X_cgdn.drop('Resistivity',axis=1,inplace=True)\n",
    "rest_index=df[features].index.isin([*X_cgdn.index,*X_dens_res.index,*X_neut_res.index,*X_pred.index])\n",
    "X_rest=df[features][~rest_index]\n",
    "X_cgr=X_rest.dropna(subset=['Compressional slowness','Gamma ray','Resistivity'])\n",
    "X_cgr=X_cgr[['Compressional slowness','Gamma ray','Resistivity']]\n",
    "last_index=df[features].index.isin([*X_cgr.index,*X_cgdn.index,*X_dens_res.index,*X_neut_res.index,*X_pred.index])\n",
    "X_last=df[features][~last_index]\n",
    "X_comp=X_last.dropna(subset=['Compressional slowness'])\n",
    "X_comp=pd.DataFrame(X_comp['Compressional slowness'])\n",
    "nocomp_index=df[features].index.isin([*X_comp.index,*X_cgr.index,*X_cgdn.index,*X_dens_res.index,*X_neut_res.index,\n",
    "                                      *X_pred.index])\n",
    "X_nocomp=df[features][~nocomp_index]\n",
    "X_nocomp['DTSM']=0\n",
    "\n",
    "from sklearn.preprocessing import MinMaxScaler, StandardScaler\n",
    "scaler=MinMaxScaler()                           \n",
    "X_pred_scaled=pd.DataFrame(scaler.fit_transform(X_pred))\n",
    "X_comp_scaled=pd.DataFrame(scaler.fit_transform(X_comp.values))\n",
    "X_neut_res_scaled=pd.DataFrame(scaler.fit_transform(X_neut_res))\n",
    "X_dens_res_scaled=pd.DataFrame(scaler.fit_transform(X_dens_res))\n",
    "X_cgdn_scaled=pd.DataFrame(scaler.fit_transform(X_cgdn))\n",
    "X_cgr_scaled=pd.DataFrame(scaler.fit_transform(X_cgr))\n",
    "\n",
    "models=['knn_reg1','knn_reg_cdgr1','knn_reg_cngr1','knn_reg_cgnd1','knn_reg_cgr1','knn_reg_comp1']\n",
    "X_preds=[X_pred,X_dens_res,X_neut_res,X_cgdn,X_cgr,X_comp]\n",
    "X_preds_scaled=[X_pred_scaled,X_dens_res_scaled,X_neut_res_scaled,X_cgdn_scaled,X_cgr_scaled,X_comp_scaled.values]\n",
    "dflist=[]\n",
    "\n",
    "for i in range(len(models)):\n",
    "    preds=pd.DataFrame(predict(models[i],X_preds[i],X_preds_scaled[i]))\n",
    "    dflist.append(preds)\n",
    "    \n",
    "dflist_f=pd.concat(dflist,axis=0)\n",
    "dff=[dflist_f,pd.DataFrame(X_nocomp['DTSM'])]\n",
    "df_comb=pd.concat(dff)\n",
    "\n",
    "df_comb=pd.DataFrame(df_comb).sort_index()\n",
    "df_f=df\n",
    "df_f['DTSM']=df_comb\n",
    "\n",
    "df_f.to_csv('Depth1.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Predictions for Depth interval 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df=df5_depth2\n",
    "features=['Resistivity','Gamma ray', 'Density', 'Neutron porosity', 'Compressional slowness']\n",
    "X=df[features]\n",
    "X_pred=X\n",
    "X_pred.dropna(inplace=True)\n",
    "rest_index=df[features].index.isin(X_pred.index)\n",
    "X_rest=df[features][~rest_index]\n",
    "X_neut_res=X_rest.dropna(subset=['Compressional slowness','Gamma ray','Neutron porosity','Resistivity'])\n",
    "X_neut_res=X_neut_res[['Compressional slowness','Gamma ray','Neutron porosity','Resistivity']]\n",
    "X_dens_res=X_rest.dropna(subset=['Compressional slowness','Gamma ray','Density','Resistivity'])\n",
    "X_dens_res=X_dens_res[['Compressional slowness','Gamma ray','Density','Resistivity']]\n",
    "nores_index=df[features].index.isin([*X_dens_res.index,*X_neut_res.index,*X_pred.index])\n",
    "X_nores=df[features][~nores_index]\n",
    "X_cgdn=X_nores.dropna(subset=['Compressional slowness','Gamma ray','Density','Neutron porosity'])\n",
    "X_cgdn.drop('Resistivity',axis=1,inplace=True)\n",
    "rest_index=df[features].index.isin([*X_cgdn.index,*X_dens_res.index,*X_neut_res.index,*X_pred.index])\n",
    "X_rest=df[features][~rest_index]\n",
    "X_cgr=X_rest.dropna(subset=['Compressional slowness','Gamma ray','Resistivity'])\n",
    "X_cgr=X_cgr[['Compressional slowness','Gamma ray','Resistivity']]\n",
    "last_index=df[features].index.isin([*X_cgr.index,*X_cgdn.index,*X_dens_res.index,*X_neut_res.index,*X_pred.index])\n",
    "X_last=df[features][~last_index]\n",
    "X_comp=X_last.dropna(subset=['Compressional slowness'])\n",
    "X_comp=pd.DataFrame(X_comp['Compressional slowness'])\n",
    "nocomp_index=df[features].index.isin([*X_comp.index,*X_cgr.index,*X_cgdn.index,*X_dens_res.index,*X_neut_res.index,\n",
    "                                      *X_pred.index])\n",
    "X_nocomp=df[features][~nocomp_index]\n",
    "X_nocomp['DTSM']=0\n",
    "\n",
    "from sklearn.preprocessing import MinMaxScaler, StandardScaler\n",
    "scaler=MinMaxScaler()                           \n",
    "X_pred_scaled=pd.DataFrame(scaler.fit_transform(X_pred))\n",
    "X_comp_scaled=pd.DataFrame(scaler.fit_transform(X_comp.values))\n",
    "X_neut_res_scaled=pd.DataFrame(scaler.fit_transform(X_neut_res))\n",
    "X_dens_res_scaled=pd.DataFrame(scaler.fit_transform(X_dens_res))\n",
    "X_cgdn_scaled=pd.DataFrame(scaler.fit_transform(X_cgdn))\n",
    "X_cgr_scaled=pd.DataFrame(scaler.fit_transform(X_cgr))\n",
    "\n",
    "models=['knn_reg2','knn_reg_cdgr2','knn_reg_cngr2','knn_reg_cgnd2','knn_reg_cgr2','knn_reg_comp2']\n",
    "X_preds=[X_pred,X_dens_res,X_neut_res,X_cgdn,X_cgr,X_comp]\n",
    "X_preds_scaled=[X_pred_scaled,X_dens_res_scaled,X_neut_res_scaled,X_cgdn_scaled,X_cgr_scaled,X_comp_scaled.values]\n",
    "dflist=[]\n",
    "\n",
    "for i in range(len(models)):\n",
    "    preds=pd.DataFrame(predict(models[i],X_preds[i],X_preds_scaled[i]))\n",
    "    dflist.append(preds)\n",
    "    \n",
    "dflist_f=pd.concat(dflist,axis=0)\n",
    "dff=[dflist_f,pd.DataFrame(X_nocomp['DTSM'])]\n",
    "df_comb=pd.concat(dff)\n",
    "\n",
    "df_comb=pd.DataFrame(df_comb).sort_index()\n",
    "df_f=df\n",
    "df_f['DTSM']=df_comb\n",
    "\n",
    "df_f.to_csv('Depth2.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Predictions for Depth interval 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df=df5_depth3\n",
    "features=['Resistivity','Gamma ray', 'Density', 'Neutron porosity', 'Compressional slowness']\n",
    "X=df[features]\n",
    "X_pred=X\n",
    "X_pred.dropna(inplace=True)\n",
    "rest_index=df[features].index.isin(X_pred.index)\n",
    "X_rest=df[features][~rest_index]\n",
    "X_neut_res=X_rest.dropna(subset=['Compressional slowness','Gamma ray','Neutron porosity','Resistivity'])\n",
    "X_neut_res=X_neut_res[['Compressional slowness','Gamma ray','Neutron porosity','Resistivity']]\n",
    "X_dens_res=X_rest.dropna(subset=['Compressional slowness','Gamma ray','Density','Resistivity'])\n",
    "X_dens_res=X_dens_res[['Compressional slowness','Gamma ray','Density','Resistivity']]\n",
    "nores_index=df[features].index.isin([*X_dens_res.index,*X_neut_res.index,*X_pred.index])\n",
    "X_nores=df[features][~nores_index]\n",
    "X_cgdn=X_nores.dropna(subset=['Compressional slowness','Gamma ray','Density','Neutron porosity'])\n",
    "X_cgdn.drop('Resistivity',axis=1,inplace=True)\n",
    "rest_index=df[features].index.isin([*X_cgdn.index,*X_dens_res.index,*X_neut_res.index,*X_pred.index])\n",
    "X_rest=df[features][~rest_index]\n",
    "X_cgr=X_rest.dropna(subset=['Compressional slowness','Gamma ray','Resistivity'])\n",
    "X_cgr=X_cgr[['Compressional slowness','Gamma ray','Resistivity']]\n",
    "last_index=df[features].index.isin([*X_cgr.index,*X_cgdn.index,*X_dens_res.index,*X_neut_res.index,*X_pred.index])\n",
    "X_last=df[features][~last_index]\n",
    "X_comp=X_last.dropna(subset=['Compressional slowness'])\n",
    "X_comp=pd.DataFrame(X_comp['Compressional slowness'])\n",
    "nocomp_index=df[features].index.isin([*X_comp.index,*X_cgr.index,*X_cgdn.index,*X_dens_res.index,*X_neut_res.index,\n",
    "                                      *X_pred.index])\n",
    "X_nocomp=df[features][~nocomp_index]\n",
    "X_nocomp['DTSM']=0\n",
    "\n",
    "from sklearn.preprocessing import MinMaxScaler, StandardScaler\n",
    "scaler=MinMaxScaler()                           \n",
    "X_pred_scaled=pd.DataFrame(scaler.fit_transform(X_pred))\n",
    "X_comp_scaled=pd.DataFrame(scaler.fit_transform(X_comp.values))\n",
    "X_neut_res_scaled=pd.DataFrame(scaler.fit_transform(X_neut_res))\n",
    "X_dens_res_scaled=pd.DataFrame(scaler.fit_transform(X_dens_res))\n",
    "X_cgdn_scaled=pd.DataFrame(scaler.fit_transform(X_cgdn))\n",
    "X_cgr_scaled=pd.DataFrame(scaler.fit_transform(X_cgr))\n",
    "\n",
    "models=['knn_reg3','knn_reg_cdgr3','knn_reg_cngr3','knn_reg_cgnd3','knn_reg_cgr3','knn_reg_comp3']\n",
    "X_preds=[X_pred,X_dens_res,X_neut_res,X_cgdn,X_cgr,X_comp]\n",
    "X_preds_scaled=[X_pred_scaled,X_dens_res_scaled,X_neut_res_scaled,X_cgdn_scaled,X_cgr_scaled,X_comp_scaled.values]\n",
    "dflist=[]\n",
    "\n",
    "for i in range(len(models)):\n",
    "    preds=pd.DataFrame(predict(models[i],X_preds[i],X_preds_scaled[i]))\n",
    "    dflist.append(preds)\n",
    "    \n",
    "dflist_f=pd.concat(dflist,axis=0)\n",
    "dff=[dflist_f,pd.DataFrame(X_nocomp['DTSM'])]\n",
    "df_comb=pd.concat(dff)\n",
    "\n",
    "df_comb=pd.DataFrame(df_comb).sort_index()\n",
    "df_f=df\n",
    "df_f['DTSM']=df_comb\n",
    "\n",
    "df_f.to_csv('Depth3.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Predictions for Depth interval 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df=df5_depth4\n",
    "features=['Resistivity','Gamma ray', 'Density', 'Neutron porosity', 'Compressional slowness']\n",
    "X=df[features]\n",
    "X_pred=X\n",
    "X_pred.dropna(inplace=True)\n",
    "rest_index=df[features].index.isin(X_pred.index)\n",
    "X_rest=df[features][~rest_index]\n",
    "X_neut_res=X_rest.dropna(subset=['Compressional slowness','Gamma ray','Neutron porosity','Resistivity'])\n",
    "X_neut_res=X_neut_res[['Compressional slowness','Gamma ray','Neutron porosity','Resistivity']]\n",
    "X_dens_res=X_rest.dropna(subset=['Compressional slowness','Gamma ray','Density','Resistivity'])\n",
    "X_dens_res=X_dens_res[['Compressional slowness','Gamma ray','Density','Resistivity']]\n",
    "nores_index=df[features].index.isin([*X_dens_res.index,*X_neut_res.index,*X_pred.index])\n",
    "X_nores=df[features][~nores_index]\n",
    "X_cgdn=X_nores.dropna(subset=['Compressional slowness','Gamma ray','Density','Neutron porosity'])\n",
    "X_cgdn.drop('Resistivity',axis=1,inplace=True)\n",
    "rest_index=df[features].index.isin([*X_cgdn.index,*X_dens_res.index,*X_neut_res.index,*X_pred.index])\n",
    "X_rest=df[features][~rest_index]\n",
    "X_cgr=X_rest.dropna(subset=['Compressional slowness','Gamma ray','Resistivity'])\n",
    "X_cgr=X_cgr[['Compressional slowness','Gamma ray','Resistivity']]\n",
    "last_index=df[features].index.isin([*X_cgr.index,*X_cgdn.index,*X_dens_res.index,*X_neut_res.index,*X_pred.index])\n",
    "X_last=df[features][~last_index]\n",
    "X_comp=X_last.dropna(subset=['Compressional slowness'])\n",
    "X_comp=pd.DataFrame(X_comp['Compressional slowness'])\n",
    "nocomp_index=df[features].index.isin([*X_comp.index,*X_cgr.index,*X_cgdn.index,*X_dens_res.index,*X_neut_res.index,\n",
    "                                      *X_pred.index])\n",
    "X_nocomp=df[features][~nocomp_index]\n",
    "X_nocomp['DTSM']=0\n",
    "\n",
    "from sklearn.preprocessing import MinMaxScaler, StandardScaler\n",
    "scaler=MinMaxScaler()\n",
    "X_pred_scaled=pd.DataFrame(scaler.fit_transform(X_pred))\n",
    "X_comp_scaled=pd.DataFrame(scaler.fit_transform(X_comp.values))\n",
    "X_neut_res_scaled=pd.DataFrame(scaler.fit_transform(X_neut_res))\n",
    "X_dens_res_scaled=pd.DataFrame(scaler.fit_transform(X_dens_res))\n",
    "X_cgdn_scaled=pd.DataFrame(scaler.fit_transform(X_cgdn))\n",
    "#X_cgr_scaled=pd.DataFrame(scaler.fit_transform(X_cgr))\n",
    "\n",
    "models=['knn_reg4','knn_reg_cdgr4','knn_reg_cngr4','knn_reg_cgnd4','knn_reg_comp4']\n",
    "X_preds=[X_pred,X_dens_res,X_neut_res,X_cgdn,X_comp]\n",
    "X_preds_scaled=[X_pred_scaled,X_dens_res_scaled,X_neut_res_scaled,X_cgdn_scaled,X_comp_scaled.values]\n",
    "dflist=[]\n",
    "\n",
    "for i in range(len(models)):\n",
    "    preds=pd.DataFrame(predict(models[i],X_preds[i],X_preds_scaled[i]))\n",
    "    dflist.append(preds)\n",
    "    \n",
    "dflist_f=pd.concat(dflist,axis=0)\n",
    "dff=[dflist_f,pd.DataFrame(X_nocomp['DTSM'])]\n",
    "df_comb=pd.concat(dff)\n",
    "\n",
    "df_comb=pd.DataFrame(df_comb).sort_index()\n",
    "df_f=df\n",
    "df_f['DTSM']=df_comb\n",
    "\n",
    "df_f.to_csv('Depth4.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Combining predictions and exporting "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_1=pd.read_csv('Depth1.csv',index_col=False)\n",
    "df_1.drop('Unnamed: 0',axis=1,inplace=True)\n",
    "\n",
    "df_2=pd.read_csv('Depth2.csv',index_col=False)\n",
    "df_2.drop('Unnamed: 0',axis=1,inplace=True)\n",
    "\n",
    "df_3=pd.read_csv('Depth3.csv',index_col=False)\n",
    "df_3.drop('Unnamed: 0',axis=1,inplace=True)\n",
    "\n",
    "df_4=pd.read_csv('Depth4.csv',index_col=False)\n",
    "df_4.drop('Unnamed: 0',axis=1,inplace=True)\n",
    "\n",
    "df_f=pd.concat([df_1,df_2,df_3,df_4])\n",
    "df_f=df_f.sort_values(['Well name','DEPT'])\n",
    "df_f.reset_index(drop=True,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_f.columns=['Resistivity', 'Gamma ray', 'Caliper', 'Photoelectric', 'Density',\n",
    "       'Neutron porosity', 'Density porosity', 'Compressional slowness',\n",
    "       'Depth', 'Well name', 'DTSM']\n",
    "UniqueNames=df_f['Well name'].unique()\n",
    "UniqueNames"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "UniqueNames=['00d02be79f49_TGS', '0a7822c59487_TGS',\n",
    "       '113412eec2a6_TGS', '1684cc35f399_TGS',\n",
    "       '20372701d5e2_TGS', '2f96a5f92418_TGS',\n",
    "       '302460e3021a_TGS', '3369b6f8fb6f_TGS',\n",
    "       '34a80ab7a5fa_TGS', '63250f7d463b_TGS',\n",
    "       '638f2cc65681_TGS', '7595ba9fb314_TGS',\n",
    "       '84c5fb9cc880_TGS', '8e37531ba266_TGS',\n",
    "       '94c1f5cae85c_TGS', 'ae16a9f64878_TGS',\n",
    "       'ed48bda2217f_TGS', 'eed1e9537976_TGS',\n",
    "       'fca03aa6acde_TGS', 'ff7845ea074d_TGS']\n",
    "\n",
    "DataFrameDict = {elem : pd.DataFrame for elem in UniqueNames}\n",
    "\n",
    "for key in DataFrameDict.keys():\n",
    "    DataFrameDict[key] = df_f[:][df_f['Well name'] == key]\n",
    "    DataFrameDict[key][['Depth','DTSM']].to_excel(key+'.xlsx',index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
